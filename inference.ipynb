{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cce7368",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dfa29c",
   "metadata": {},
   "source": [
    "We will run inference on the true holdout set of 30k rows and save our results, and then plot those results in another notebook for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f274507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9725fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/final_holdout_x.csv')\n",
    "y = pd.read_csv('data/final_holdout_y.csv')\n",
    "s = X['race']\n",
    "X = X.drop('race', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e1469",
   "metadata": {},
   "source": [
    "## Balanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca78624",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c299950",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/balanced_LR.joblib')\n",
    "scaler = joblib.load('scaler/balanced_lr_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3cc3627",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.transform(X)\n",
    "ypreds = model.predict(x)\n",
    "yprobs = model.predict_proba(x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef7fd00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of yprob: (29995,)\n",
      "Shape of ytest: (29995, 1)\n",
      "Shape of races: (29995,)\n",
      "Length of ytest: 29995\n",
      "Length of ypred: 29995\n",
      "Length of races: 29995\n",
      "Type of races: <class 'pandas.core.series.Series'>\n",
      "Type of ytest: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of ypred: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of yprob: {yprobs.shape}\")\n",
    "print(f\"Shape of ytest: {y.shape}\")\n",
    "print(f\"Shape of races: {s.shape}\")\n",
    "\n",
    "print(f\"Length of ytest: {len(y)}\")\n",
    "print(f\"Length of ypred: {len(ypreds)}\")\n",
    "print(f\"Length of races: {len(s)}\")\n",
    "\n",
    "print(f\"Type of races: {type(s)}\")\n",
    "print(f\"Type of ytest: {type(y)}\")\n",
    "print(f\"Type of ypred: {type(ypreds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e8aa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True_Label  Probability  Predicted_Label             race\n",
      "0           0     0.008250                0         Hispanic\n",
      "1           0     0.000684                0         Hispanic\n",
      "2           0     0.002228                0  AfricanAmerican\n",
      "3           0     0.261786                0        Caucasian\n",
      "4           0     0.005791                0            Asian\n",
      "Final DataFrame shape: (29995, 4)\n"
     ]
    }
   ],
   "source": [
    "yprob_series = pd.Series(yprobs, name='Probability')\n",
    "ypred_series = pd.Series(ypreds, name='Predicted_Label')\n",
    "y.columns = ['True_Label']\n",
    "\n",
    "data_list = [y, yprob_series, ypred_series, s]\n",
    "columnar_df = pd.concat(data_list, axis=1)\n",
    "\n",
    "print(columnar_df.head())\n",
    "print(f\"Final DataFrame shape: {columnar_df.shape}\")\n",
    "\n",
    "columnar_df.to_csv('inference/LR_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a575b",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e42eab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/balanced_RF.joblib')\n",
    "scaler = joblib.load('scaler/balanced_RF_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9f0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.transform(X)\n",
    "ypreds = model.predict(x)\n",
    "yprobs = model.predict_proba(x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c6e42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of yprob: (29995,)\n",
      "Shape of ytest: (29995, 1)\n",
      "Shape of races: (29995,)\n",
      "Length of ytest: 29995\n",
      "Length of ypred: 29995\n",
      "Length of races: 29995\n",
      "Type of races: <class 'pandas.core.series.Series'>\n",
      "Type of ytest: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of ypred: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of yprob: {yprobs.shape}\")\n",
    "print(f\"Shape of ytest: {y.shape}\")\n",
    "print(f\"Shape of races: {s.shape}\")\n",
    "\n",
    "print(f\"Length of ytest: {len(y)}\")\n",
    "print(f\"Length of ypred: {len(ypreds)}\")\n",
    "print(f\"Length of races: {len(s)}\")\n",
    "\n",
    "print(f\"Type of races: {type(s)}\")\n",
    "print(f\"Type of ytest: {type(y)}\")\n",
    "print(f\"Type of ypred: {type(ypreds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa01e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True_Label  Probability  Predicted_Label             race\n",
      "0           0         0.01                0         Hispanic\n",
      "1           0         0.00                0         Hispanic\n",
      "2           0         0.01                0  AfricanAmerican\n",
      "3           0         0.00                0        Caucasian\n",
      "4           0         0.01                0            Asian\n",
      "Final DataFrame shape: (29995, 4)\n"
     ]
    }
   ],
   "source": [
    "yprob_series = pd.Series(yprobs, name='Probability')\n",
    "ypred_series = pd.Series(ypreds, name='Predicted_Label')\n",
    "y.columns = ['True_Label']\n",
    "\n",
    "data_list = [y, yprob_series, ypred_series, s]\n",
    "columnar_df = pd.concat(data_list, axis=1)\n",
    "\n",
    "print(columnar_df.head())\n",
    "print(f\"Final DataFrame shape: {columnar_df.shape}\")\n",
    "\n",
    "columnar_df.to_csv('inference/RF_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d668cf",
   "metadata": {},
   "source": [
    "## Biased Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064e110",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c029780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/caucasian_biased_LR.joblib')\n",
    "scaler = joblib.load('scaler/caucasian_lr_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2d210eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.transform(X)\n",
    "ypreds = model.predict(x)\n",
    "yprobs = model.predict_proba(x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cca4d24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of yprob: (29995,)\n",
      "Shape of ytest: (29995, 1)\n",
      "Shape of races: (29995,)\n",
      "Length of ytest: 29995\n",
      "Length of ypred: 29995\n",
      "Length of races: 29995\n",
      "Type of races: <class 'pandas.core.series.Series'>\n",
      "Type of ytest: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of ypred: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of yprob: {yprobs.shape}\")\n",
    "print(f\"Shape of ytest: {y.shape}\")\n",
    "print(f\"Shape of races: {s.shape}\")\n",
    "\n",
    "print(f\"Length of ytest: {len(y)}\")\n",
    "print(f\"Length of ypred: {len(ypreds)}\")\n",
    "print(f\"Length of races: {len(s)}\")\n",
    "\n",
    "print(f\"Type of races: {type(s)}\")\n",
    "print(f\"Type of ytest: {type(y)}\")\n",
    "print(f\"Type of ypred: {type(ypreds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc148f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True_Label  Probability  Predicted_Label             race\n",
      "0           0     0.008052                0         Hispanic\n",
      "1           0     0.000630                0         Hispanic\n",
      "2           0     0.002638                0  AfricanAmerican\n",
      "3           0     0.273729                0        Caucasian\n",
      "4           0     0.004286                0            Asian\n",
      "Final DataFrame shape: (29995, 4)\n"
     ]
    }
   ],
   "source": [
    "yprob_series = pd.Series(yprobs, name='Probability')\n",
    "ypred_series = pd.Series(ypreds, name='Predicted_Label')\n",
    "y.columns = ['True_Label']\n",
    "\n",
    "data_list = [y, yprob_series, ypred_series, s]\n",
    "columnar_df = pd.concat(data_list, axis=1)\n",
    "\n",
    "print(columnar_df.head())\n",
    "print(f\"Final DataFrame shape: {columnar_df.shape}\")\n",
    "\n",
    "columnar_df.to_csv('inference/LR_biased.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585000d",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80665050",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/caucasian_biased_RF.joblib')\n",
    "scaler = joblib.load('scaler/caucasian_rf_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8036e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.transform(X)\n",
    "ypreds = model.predict(x)\n",
    "yprobs = model.predict_proba(x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48807ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of yprob: (29995,)\n",
      "Shape of ytest: (29995, 1)\n",
      "Shape of races: (29995,)\n",
      "Length of ytest: 29995\n",
      "Length of ypred: 29995\n",
      "Length of races: 29995\n",
      "Type of races: <class 'pandas.core.series.Series'>\n",
      "Type of ytest: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of ypred: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of yprob: {yprobs.shape}\")\n",
    "print(f\"Shape of ytest: {y.shape}\")\n",
    "print(f\"Shape of races: {s.shape}\")\n",
    "\n",
    "print(f\"Length of ytest: {len(y)}\")\n",
    "print(f\"Length of ypred: {len(ypreds)}\")\n",
    "print(f\"Length of races: {len(s)}\")\n",
    "\n",
    "print(f\"Type of races: {type(s)}\")\n",
    "print(f\"Type of ytest: {type(y)}\")\n",
    "print(f\"Type of ypred: {type(ypreds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3353e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True_Label  Probability  Predicted_Label             race\n",
      "0           0         0.01                0         Hispanic\n",
      "1           0         0.00                0         Hispanic\n",
      "2           0         0.05                0  AfricanAmerican\n",
      "3           0         0.00                0        Caucasian\n",
      "4           0         0.03                0            Asian\n",
      "Final DataFrame shape: (29995, 4)\n"
     ]
    }
   ],
   "source": [
    "yprob_series = pd.Series(yprobs, name='Probability')\n",
    "ypred_series = pd.Series(ypreds, name='Predicted_Label')\n",
    "y.columns = ['True_Label']\n",
    "\n",
    "data_list = [y, yprob_series, ypred_series, s]\n",
    "columnar_df = pd.concat(data_list, axis=1)\n",
    "\n",
    "print(columnar_df.head())\n",
    "print(f\"Final DataFrame shape: {columnar_df.shape}\")\n",
    "\n",
    "columnar_df.to_csv('inference/RF_biased.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0f127",
   "metadata": {},
   "source": [
    "## Biased + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7766b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/caucasian_smote_LR.joblib')\n",
    "scaler = joblib.load('scaler/smote_caucasian_lr_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5176ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.transform(X)\n",
    "ypreds = model.predict(x)\n",
    "yprobs = model.predict_proba(x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bf174e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of yprob: (29995,)\n",
      "Shape of ytest: (29995, 1)\n",
      "Shape of races: (29995,)\n",
      "Length of ytest: 29995\n",
      "Length of ypred: 29995\n",
      "Length of races: 29995\n",
      "Type of races: <class 'pandas.core.series.Series'>\n",
      "Type of ytest: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of ypred: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of yprob: {yprobs.shape}\")\n",
    "print(f\"Shape of ytest: {y.shape}\")\n",
    "print(f\"Shape of races: {s.shape}\")\n",
    "\n",
    "print(f\"Length of ytest: {len(y)}\")\n",
    "print(f\"Length of ypred: {len(ypreds)}\")\n",
    "print(f\"Length of races: {len(s)}\")\n",
    "\n",
    "print(f\"Type of races: {type(s)}\")\n",
    "print(f\"Type of ytest: {type(y)}\")\n",
    "print(f\"Type of ypred: {type(ypreds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "511617cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True_Label  Probability  Predicted_Label             race\n",
      "0           0     0.002030                0         Hispanic\n",
      "1           0     0.000290                0         Hispanic\n",
      "2           0     0.000509                0  AfricanAmerican\n",
      "3           0     0.123914                0        Caucasian\n",
      "4           0     0.001281                0            Asian\n",
      "Final DataFrame shape: (29995, 4)\n"
     ]
    }
   ],
   "source": [
    "yprob_series = pd.Series(yprobs, name='Probability')\n",
    "ypred_series = pd.Series(ypreds, name='Predicted_Label')\n",
    "y.columns = ['True_Label']\n",
    "\n",
    "data_list = [y, yprob_series, ypred_series, s]\n",
    "columnar_df = pd.concat(data_list, axis=1)\n",
    "\n",
    "print(columnar_df.head())\n",
    "print(f\"Final DataFrame shape: {columnar_df.shape}\")\n",
    "\n",
    "columnar_df.to_csv('inference/holdout_lr_SMOTE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785867d2",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48b8b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/caucasian_smote_RF.joblib')\n",
    "scaler = joblib.load('scaler/caucasian_smote_RF_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf2bea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.transform(X)\n",
    "ypreds = model.predict(x)\n",
    "yprobs = model.predict_proba(x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78911e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of yprob: (29995,)\n",
      "Shape of ytest: (29995, 1)\n",
      "Shape of races: (29995,)\n",
      "Length of ytest: 29995\n",
      "Length of ypred: 29995\n",
      "Length of races: 29995\n",
      "Type of races: <class 'pandas.core.series.Series'>\n",
      "Type of ytest: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of ypred: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of yprob: {yprobs.shape}\")\n",
    "print(f\"Shape of ytest: {y.shape}\")\n",
    "print(f\"Shape of races: {s.shape}\")\n",
    "\n",
    "print(f\"Length of ytest: {len(y)}\")\n",
    "print(f\"Length of ypred: {len(ypreds)}\")\n",
    "print(f\"Length of races: {len(s)}\")\n",
    "\n",
    "print(f\"Type of races: {type(s)}\")\n",
    "print(f\"Type of ytest: {type(y)}\")\n",
    "print(f\"Type of ypred: {type(ypreds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eb67745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True_Label  Probability  Predicted_Label             race\n",
      "0           0         0.00                0         Hispanic\n",
      "1           0         0.00                0         Hispanic\n",
      "2           0         0.08                0  AfricanAmerican\n",
      "3           0         0.00                0        Caucasian\n",
      "4           0         0.00                0            Asian\n",
      "Final DataFrame shape: (29995, 4)\n"
     ]
    }
   ],
   "source": [
    "yprob_series = pd.Series(yprobs, name='Probability')\n",
    "ypred_series = pd.Series(ypreds, name='Predicted_Label')\n",
    "y.columns = ['True_Label']\n",
    "\n",
    "data_list = [y, yprob_series, ypred_series, s]\n",
    "columnar_df = pd.concat(data_list, axis=1)\n",
    "\n",
    "print(columnar_df.head())\n",
    "print(f\"Final DataFrame shape: {columnar_df.shape}\")\n",
    "\n",
    "columnar_df.to_csv('inference/holdout_RF_SMOTE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4b054",
   "metadata": {},
   "source": [
    "## Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "673a4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "scaler = joblib.load('scaler/balanced_lr_scaler.joblib')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from case_three import AdversarialPipeline,INPUT_SIZE, NUM_CLASSES, NUM_SENSITIVE_GROUPS # Constants\n",
    "\n",
    "# --- Configuration (MUST match training setup) ---\n",
    "CHECKPOINT_PATH = \"best_adversarial_pipeline_checkpoint.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Or 'mps'\n",
    "FEATURE_DIM = 32 # Must match the value used during training!\n",
    "\n",
    "# --- Temporary Dataset for Inference (No targets needed) ---\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        # Ensure input is a NumPy array/list for tensor conversion\n",
    "        if isinstance(X_data, pd.DataFrame):\n",
    "            X_data = X_data.values\n",
    "        self.X = torch.tensor(X_data, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Only returns the feature data\n",
    "        return self.X[idx]\n",
    "\n",
    "def get_y_logits_for_class_1(X: pd.DataFrame, scaler, batch_size=256):\n",
    "    \"\"\"\n",
    "    Scales input data, loads the trained model, and returns raw logits \n",
    "    for the positive class (class 1).\n",
    "    \n",
    "    :param X: Input features as a pandas DataFrame.\n",
    "    :param scaler: The fitted StandardScaler object from training.\n",
    "    :param batch_size: Batch size for DataLoader.\n",
    "    :return: NumPy array of logits for class 1.\n",
    "    \"\"\"\n",
    "    # 1. Preprocessing: Scaling X\n",
    "    print(\"1. Scaling input data...\")\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # 2. Dataset/DataLoader Setup\n",
    "    inference_dataset = InferenceDataset(X_scaled)\n",
    "    inference_loader = DataLoader(\n",
    "        inference_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    # 3. Model Setup: Instantiate and Load Weights\n",
    "    print(\"2. Loading model checkpoint...\")\n",
    "    pipeline = AdversarialPipeline(\n",
    "        input_size=INPUT_SIZE, \n",
    "        feature_dim=FEATURE_DIM, \n",
    "        num_classes=NUM_CLASSES, \n",
    "        num_sensitive_groups=NUM_SENSITIVE_GROUPS\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    pipeline.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # 4. Inference Loop\n",
    "    pipeline.eval()\n",
    "    all_logits = []\n",
    "    \n",
    "    print(\"3. Running inference loop...\")\n",
    "    with torch.no_grad():\n",
    "        for x_batch in inference_loader:\n",
    "            # x_batch is a list/tuple of size 1 since InferenceDataset returns one item\n",
    "            x_batch = x_batch.to(DEVICE) \n",
    "            \n",
    "            # Forward pass: y_pred_logits comes from the F -> C path\n",
    "            y_pred_logits, _ = pipeline(x_batch) \n",
    "            \n",
    "            # Extract the logit for the positive class (class index 1)\n",
    "            # This is essential for binary classification (0, 1)\n",
    "            logits_class_1 = y_pred_logits[:, 1] \n",
    "            \n",
    "            all_logits.append(logits_class_1.cpu().numpy())\n",
    "            \n",
    "    # Combine batches into a single NumPy array\n",
    "    final_logits = np.concatenate(all_logits)\n",
    "    print(\"Inference complete.\")\n",
    "    return final_logits\n",
    "\n",
    "# --- Example of How to Use the Function ---\n",
    "# Assume X is your loaded DataFrame and scaler is your loaded StandardScaler\n",
    "# E.g., X = pd.read_csv(\"unseen_data.csv\").drop(columns=['target'])\n",
    "# E.g., scaler = loaded_scaler_object \n",
    "\n",
    "\n",
    "# print(\"Shape of output logits:\", y_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bbae45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Scaling input data...\n",
      "2. Loading model checkpoint...\n",
      "3. Running inference loop...\n",
      "Inference complete.\n"
     ]
    }
   ],
   "source": [
    "y_logits = get_y_logits_for_class_1(X, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b64f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities calculated (using Sigmoid).\n",
      "Binary predictions calculated (using threshold=0.5).\n",
      "\n",
      "First 5 Raw Logits: [-2.300472  -3.4964902 -2.445289  -1.4030709 -2.9335432]\n",
      "First 5 Probabilities: [0.09108388 0.02941226 0.07978375 0.19732925 0.0505201 ]\n",
      "First 5 Binary Predictions: [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Encoding Logits and Final Probabilities\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import expit # Sigmoid function for converting logit to probability\n",
    "\n",
    "# Assume y_logits is the NumPy array output from the function in Code Block 1\n",
    "# y_logits = np.array([1.5, -0.2, 3.0, -4.5, 0.1]) \n",
    "\n",
    "def encode_logits(y_logits: np.ndarray, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Converts raw logits for class 1 into probabilities and hard binary predictions.\n",
    "    \n",
    "    :param y_logits: NumPy array of logits (output of the final layer for class 1).\n",
    "    :param threshold: Probability threshold for hard binary prediction.\n",
    "    :return: A tuple (y_probs, y_preds_binary)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Convert Logits to Probabilities (using Sigmoid)\n",
    "    # For binary classification (our case), P(class 1) = Sigmoid(logit)\n",
    "    # This is equivalent to softmax(logits)[..., 1]\n",
    "    y_probs = expit(y_logits)\n",
    "    \n",
    "    # 2. Convert Probabilities to Hard Binary Predictions\n",
    "    # If P(class 1) > threshold, predict 1, else predict 0\n",
    "    y_preds_binary = (y_probs >= threshold).astype(int)\n",
    "    \n",
    "    print(f\"Probabilities calculated (using Sigmoid).\")\n",
    "    print(f\"Binary predictions calculated (using threshold={threshold}).\")\n",
    "    \n",
    "    return y_probs, y_preds_binary\n",
    "\n",
    "# --- Example of How to Use the Function ---\n",
    "\n",
    "# Assuming y_logits has been returned by get_y_logits_for_class_1(X, scaler)\n",
    "y_probs_final, y_preds_final = encode_logits(y_logits)\n",
    "\n",
    "print(\"\\nFirst 5 Raw Logits:\", y_logits[:5])\n",
    "print(\"First 5 Probabilities:\", y_probs_final[:5])\n",
    "print(\"First 5 Binary Predictions:\", y_preds_final[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f55eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yprobs = y_probs_final\n",
    "ypreds = y_preds_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "196436ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of yprob: (29995,)\n",
      "Shape of ytest: (29995, 1)\n",
      "Shape of races: (29995,)\n",
      "Length of ytest: 29995\n",
      "Length of ypred: 29995\n",
      "Length of races: 29995\n",
      "Type of races: <class 'pandas.core.series.Series'>\n",
      "Type of ytest: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of ypred: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of yprob: {yprobs.shape}\")\n",
    "print(f\"Shape of ytest: {y.shape}\")\n",
    "print(f\"Shape of races: {s.shape}\")\n",
    "\n",
    "print(f\"Length of ytest: {len(y)}\")\n",
    "print(f\"Length of ypred: {len(ypreds)}\")\n",
    "print(f\"Length of races: {len(s)}\")\n",
    "\n",
    "print(f\"Type of races: {type(s)}\")\n",
    "print(f\"Type of ytest: {type(y)}\")\n",
    "print(f\"Type of ypred: {type(ypreds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ca726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True_Label  Probability  Predicted_Label             race\n",
      "0           0     0.091084                0         Hispanic\n",
      "1           0     0.029412                0         Hispanic\n",
      "2           0     0.079784                0  AfricanAmerican\n",
      "3           0     0.197329                0        Caucasian\n",
      "4           0     0.050520                0            Asian\n",
      "Final DataFrame shape: (29995, 4)\n"
     ]
    }
   ],
   "source": [
    "yprob_series = pd.Series(yprobs, name='Probability')\n",
    "ypred_series = pd.Series(ypreds, name='Predicted_Label')\n",
    "y.columns = ['True_Label']\n",
    "\n",
    "data_list = [y, yprob_series, ypred_series, s]\n",
    "columnar_df = pd.concat(data_list, axis=1)\n",
    "\n",
    "print(columnar_df.head())\n",
    "print(f\"Final DataFrame shape: {columnar_df.shape}\")\n",
    "\n",
    "columnar_df.to_csv('inference/holdout_adv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc57395",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parkinsons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
